{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf # Here I use tensorflow version 2.2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length :  891\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Age Cabin Embarked     Fare  \\\n0  22.0   NaN        S   7.2500   \n1  38.0   C85        C  71.2833   \n2  26.0   NaN        S   7.9250   \n3  35.0  C123        S  53.1000   \n4  35.0   NaN        S   8.0500   \n\n                                                Name  Parch  PassengerId  \\\n0                            Braund, Mr. Owen Harris      0            1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n2                             Heikkinen, Miss. Laina      0            3   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n4                           Allen, Mr. William Henry      0            5   \n\n   Pclass     Sex  SibSp  Survived            Ticket Title  Family_Size  \n0       3    male      1       0.0         A/5 21171    Mr            1  \n1       1  female      1       1.0          PC 17599   Mrs            1  \n2       3  female      0       1.0  STON/O2. 3101282  Miss            0  \n3       1  female      1       1.0            113803   Mrs            1  \n4       3    male      0       0.0            373450    Mr            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Fare</th>\n      <th>Name</th>\n      <th>Parch</th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>SibSp</th>\n      <th>Survived</th>\n      <th>Ticket</th>\n      <th>Title</th>\n      <th>Family_Size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>7.2500</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>male</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>A/5 21171</td>\n      <td>Mr</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>71.2833</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>female</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>PC 17599</td>\n      <td>Mrs</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>7.9250</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>female</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>STON/O2. 3101282</td>\n      <td>Miss</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>53.1000</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>female</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>113803</td>\n      <td>Mrs</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>8.0500</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>373450</td>\n      <td>Mr</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Read csv using pandas\n",
    "data = pd.read_csv('./train_clean.csv', index_col=False)\n",
    "print('Length : ', len(data))\n",
    "data.head() # Print top 5 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of training samples :  712\nNumber of test samples :  179\n"
    }
   ],
   "source": [
    "# Split the data into training and testing data \n",
    "# 80% for training and 20% for testing\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "print('Number of training samples : ',len(train_data))\n",
    "print('Number of test samples : ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "For training ...\nAge              0\nCabin          555\nEmbarked         0\nFare             0\nName             0\nParch            0\nPassengerId      0\nPclass           0\nSex              0\nSibSp            0\nSurvived         0\nTicket           0\nTitle            0\nFamily_Size      0\ndtype: int64\nFor testing ...\nAge              0\nCabin          132\nEmbarked         0\nFare             0\nName             0\nParch            0\nPassengerId      0\nPclass           0\nSex              0\nSibSp            0\nSurvived         0\nTicket           0\nTitle            0\nFamily_Size      0\ndtype: int64\n"
    }
   ],
   "source": [
    "# Count the number of null values in each column for both training and testing data\n",
    "print('For training ...')\n",
    "print(train_data.isna().sum())\n",
    "\n",
    "print('For testing ...')\n",
    "print(test_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null valued column \"Cabin\"\n",
    "# Here we remove the entire column since we have more null values than the actual values\n",
    "train_data.drop('Cabin', axis=1, inplace=True)\n",
    "test_data.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "For training ...\nAge            0\nEmbarked       0\nFare           0\nName           0\nParch          0\nPassengerId    0\nPclass         0\nSex            0\nSibSp          0\nSurvived       0\nTicket         0\nTitle          0\nFamily_Size    0\ndtype: int64\n\nFor testing ...\nAge            0\nEmbarked       0\nFare           0\nName           0\nParch          0\nPassengerId    0\nPclass         0\nSex            0\nSibSp          0\nSurvived       0\nTicket         0\nTitle          0\nFamily_Size    0\ndtype: int64\n"
    }
   ],
   "source": [
    "# Count the number of null values in each column for both training and testing data\n",
    "print('For training ...')\n",
    "print(train_data.isna().sum())\n",
    "\n",
    "print('\\nFor testing ...')\n",
    "print(test_data.isna().sum())\n",
    "\n",
    "# From the below result we can conclude that there is no null values left in out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove other unneccesary columns\n",
    "\n",
    "# Remove Name column since it is different for different people and have nothing to do with survival\n",
    "train_data.drop('Name', axis=1, inplace=True)\n",
    "test_data.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Similarly drop Fare, PassengerId, Ticket\n",
    "train_data.drop('Fare', axis=1, inplace=True)\n",
    "test_data.drop('Fare', axis=1, inplace=True)\n",
    "\n",
    "train_data.drop('PassengerId', axis=1, inplace=True)\n",
    "test_data.drop('PassengerId', axis=1, inplace=True)\n",
    "\n",
    "train_data.drop('Ticket', axis=1, inplace=True)\n",
    "test_data.drop('Ticket', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target column from the data and store it in a separate variable \n",
    "train_label = train_data.pop('Survived')\n",
    "test_label = test_data.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "359    1.0\n747    1.0\n370    1.0\n659    0.0\n637    0.0\nName: Survived, dtype: float64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Print top 5 labels in test set\n",
    "test_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of traing data:  712\nLength of training label :  712\nLength of test data:  179\nLength of test label :  179\n"
    }
   ],
   "source": [
    "print('Length of traing data: ', len(train_data))\n",
    "print('Length of training label : ', len(train_label))\n",
    "print('Length of test data: ', len(test_data))\n",
    "print('Length of test label : ', len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train input function\n",
    "def create_train_input_fn():\n",
    "    '''\n",
    "    Returns input function that would feed pandas Dataframe into model for training\n",
    "    '''\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x = train_data,\n",
    "        y = train_label,\n",
    "        batch_size = 8, # Update parameters for every 8 training samples\n",
    "        num_epochs = None, # Since we pass it multiple times through the network\n",
    "        shuffle= True \n",
    "    )\n",
    "\n",
    "#Create test input function\n",
    "def create_test_input_fn():\n",
    "    '''\n",
    "    Returns input function that would feed pandas Dataframe into model for testing\n",
    "    '''\n",
    "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "        x = test_data,\n",
    "        y = test_label,\n",
    "        num_epochs = 1, # Pass only one iteration while testing\n",
    "        shuffle= False # No need of shuffling test set\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base feature columns\n",
    "feature_list = []\n",
    "\n",
    "CATEGORICAL_COLUMN = ['Embarked', 'Sex', 'Title'] # Column name containing string values\n",
    "NUMERICAL_COLUMN = ['Age', 'Parch', 'Pclass', 'SibSp', 'Family_Size'] # Column name containing numerical values\n",
    "\n",
    "for feature_name in CATEGORICAL_COLUMN:\n",
    "    vocab = train_data[feature_name].unique() # This returns a list of unique values in the column\n",
    "    feature_list.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocab))\n",
    "\n",
    "for feature_name in NUMERICAL_COLUMN:\n",
    "    feature_list.append(tf.feature_column.numeric_column(feature_name, dtype = tf.int32)) # Represents numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\Users\\KRISHNA PRASAD P\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n\nINFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': './graphs/linear', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\nWARNING:tensorflow:From C:\\Users\\KRISHNA PRASAD P\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From C:\\Users\\KRISHNA PRASAD P\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\nWARNING:tensorflow:From C:\\Users\\KRISHNA PRASAD P\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:65: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nWARNING:tensorflow:From C:\\Users\\KRISHNA PRASAD P\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nINFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nWARNING:tensorflow:From C:\\Users\\KRISHNA PRASAD P\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:540: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `layer.add_weight` method instead.\nWARNING:tensorflow:From C:\\Users\\KRISHNA PRASAD P\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nWARNING:tensorflow:From C:\\Users\\KRISHNA PRASAD P\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nINFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\nINFO:tensorflow:Saving checkpoints for 0 into ./graphs/linear\\model.ckpt.\nINFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\nINFO:tensorflow:loss = 0.6931472, step = 0\nINFO:tensorflow:global_step/sec: 135.658\nINFO:tensorflow:loss = 0.7512396, step = 100 (0.749 sec)\nINFO:tensorflow:global_step/sec: 219.288\nINFO:tensorflow:loss = 0.11541262, step = 200 (0.451 sec)\nINFO:tensorflow:global_step/sec: 207.146\nINFO:tensorflow:loss = 0.23651236, step = 300 (0.481 sec)\nINFO:tensorflow:global_step/sec: 231.589\nINFO:tensorflow:loss = 0.49691644, step = 400 (0.445 sec)\nINFO:tensorflow:global_step/sec: 214.405\nINFO:tensorflow:loss = 0.5753329, step = 500 (0.456 sec)\nINFO:tensorflow:global_step/sec: 219.642\nINFO:tensorflow:loss = 0.2014049, step = 600 (0.460 sec)\nINFO:tensorflow:global_step/sec: 207.138\nINFO:tensorflow:loss = 0.20183244, step = 700 (0.484 sec)\nINFO:tensorflow:global_step/sec: 226.253\nINFO:tensorflow:loss = 0.31068277, step = 800 (0.437 sec)\nINFO:tensorflow:global_step/sec: 262.119\nINFO:tensorflow:loss = 0.41174588, step = 900 (0.380 sec)\nINFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\nINFO:tensorflow:Saving checkpoints for 1000 into ./graphs/linear\\model.ckpt.\nINFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\nINFO:tensorflow:Loss for final step: 0.52934545.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x1ef872c2b48>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Create an instance of input funtion\n",
    "input_train_fn = create_train_input_fn()\n",
    "\n",
    "# Create an instance of Linear Classifier estimator\n",
    "# This writes log to the graphs/linear folder\n",
    "# Every time you train, it resumes from the latest check point\n",
    "# For training from beginning, make sure you clean the log directory before you train\n",
    "estimator = tf.estimator.LinearClassifier(feature_list, model_dir='./graphs/linear', n_classes=2)\n",
    "\n",
    "# Train the estimator\n",
    "estimator.train(input_train_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2020-07-04T20:07:54Z\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from ./graphs/linear\\model.ckpt-1000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Inference Time : 1.57819s\nINFO:tensorflow:Finished evaluation at 2020-07-04-20:07:56\nINFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8156425, accuracy_baseline = 0.61452514, auc = 0.90013176, auc_precision_recall = 0.8701625, average_loss = 0.45590118, global_step = 1000, label/mean = 0.38547486, loss = 0.469847, precision = 0.70454544, prediction/mean = 0.52929664, recall = 0.89855075\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ./graphs/linear\\model.ckpt-1000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': 0.8156425,\n 'accuracy_baseline': 0.61452514,\n 'auc': 0.90013176,\n 'auc_precision_recall': 0.8701625,\n 'average_loss': 0.45590118,\n 'label/mean': 0.38547486,\n 'loss': 0.469847,\n 'precision': 0.70454544,\n 'prediction/mean': 0.52929664,\n 'recall': 0.89855075,\n 'global_step': 1000}"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "# Create an instance of test input function\n",
    "input_test_fn = create_test_input_fn()\n",
    "\n",
    "# Pass input_test_fn as an argument to the evaluate function\n",
    "# This will print the accuracy along with other performance measures\n",
    "estimator.evaluate(input_test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from ./graphs/linear\\model.ckpt-1000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n\n Example : 0 \t Actual : 1.0 \t Predicted : 1\n\n Example : 1 \t Actual : 1.0 \t Predicted : 1\n\n Example : 2 \t Actual : 1.0 \t Predicted : 1\n\n Example : 3 \t Actual : 0.0 \t Predicted : 1\n\n Example : 4 \t Actual : 0.0 \t Predicted : 0\n\n Example : 5 \t Actual : 1.0 \t Predicted : 1\n\n Example : 6 \t Actual : 1.0 \t Predicted : 1\n\n Example : 7 \t Actual : 1.0 \t Predicted : 1\n\n Example : 8 \t Actual : 0.0 \t Predicted : 0\n\n Example : 9 \t Actual : 0.0 \t Predicted : 0\n"
    }
   ],
   "source": [
    "# Predict output for test set\n",
    "input_test_fn = create_test_input_fn()\n",
    "result = estimator.predict(input_test_fn)\n",
    "\n",
    "# Verify results\n",
    "i = 0\n",
    "for res,actual_result in zip(result, test_label):\n",
    "    predicted_result = res['class_ids'][0]\n",
    "    print(\"\\n Example : {} \\t Actual : {} \\t Predicted : {}\".format(i, actual_result, predicted_result))\n",
    "\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DNN Classifier \n",
    "\n",
    "# Let's create a vocabulary list for features with fewer categorical values\n",
    "\n",
    "Embarked = tf.feature_column.categorical_column_with_vocabulary_list('Embarked',train_data['Embarked'].unique())\n",
    "\n",
    "Sex = tf.feature_column.categorical_column_with_vocabulary_list('Sex',train_data['Sex'].unique())\n",
    "\n",
    "Title = tf.feature_column.categorical_column_with_vocabulary_list('Title',train_data['Title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature column\n",
    "feature_columns = [\n",
    "    # Indicator column represents multi-hot representation of given categorical column\n",
    "    tf.feature_column.indicator_column(Embarked),\n",
    "    tf.feature_column.indicator_column(Sex),\n",
    "    tf.feature_column.indicator_column(Title),\n",
    "\n",
    "    # Let's include numerical columns as well\n",
    "    tf.feature_column.numeric_column('Age'),\n",
    "    tf.feature_column.numeric_column('Parch'),\n",
    "    tf.feature_column.numeric_column('Pclass'),\n",
    "    tf.feature_column.numeric_column('SibSp'),\n",
    "    tf.feature_column.numeric_column('Family_Size')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': './graphs/dnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
    }
   ],
   "source": [
    "# Create DNN estimator\n",
    "\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[256, 128, 64], # Number of units in each hidden layer\n",
    "    # Here we have 3 hidden layers\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=2, # Since we have 2 output classes\n",
    "    model_dir='./graphs/dnn' # For storing the checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\nINFO:tensorflow:Saving checkpoints for 0 into ./graphs/dnn\\model.ckpt.\nINFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\nINFO:tensorflow:loss = 0.5733564, step = 0\nINFO:tensorflow:global_step/sec: 214.097\nINFO:tensorflow:loss = 0.5432509, step = 100 (0.472 sec)\nINFO:tensorflow:global_step/sec: 287.06\nINFO:tensorflow:loss = 0.65536857, step = 200 (0.348 sec)\nINFO:tensorflow:global_step/sec: 320.519\nINFO:tensorflow:loss = 0.7217245, step = 300 (0.309 sec)\nINFO:tensorflow:global_step/sec: 333.62\nINFO:tensorflow:loss = 0.72600096, step = 400 (0.299 sec)\nINFO:tensorflow:global_step/sec: 336.258\nINFO:tensorflow:loss = 0.49092692, step = 500 (0.299 sec)\nINFO:tensorflow:global_step/sec: 329.056\nINFO:tensorflow:loss = 0.47468203, step = 600 (0.303 sec)\nINFO:tensorflow:global_step/sec: 228.269\nINFO:tensorflow:loss = 0.49019307, step = 700 (0.440 sec)\nINFO:tensorflow:global_step/sec: 227.503\nINFO:tensorflow:loss = 0.4266697, step = 800 (0.459 sec)\nINFO:tensorflow:global_step/sec: 247.473\nINFO:tensorflow:loss = 0.5346917, step = 900 (0.384 sec)\nINFO:tensorflow:global_step/sec: 316.317\nINFO:tensorflow:loss = 0.4579292, step = 1000 (0.317 sec)\nINFO:tensorflow:global_step/sec: 245.493\nINFO:tensorflow:loss = 0.62138844, step = 1100 (0.415 sec)\nINFO:tensorflow:global_step/sec: 246.697\nINFO:tensorflow:loss = 0.42297322, step = 1200 (0.409 sec)\nINFO:tensorflow:global_step/sec: 251.887\nINFO:tensorflow:loss = 0.98990625, step = 1300 (0.382 sec)\nINFO:tensorflow:global_step/sec: 276.389\nINFO:tensorflow:loss = 0.39451402, step = 1400 (0.361 sec)\nINFO:tensorflow:global_step/sec: 284.575\nINFO:tensorflow:loss = 0.44481102, step = 1500 (0.355 sec)\nINFO:tensorflow:global_step/sec: 285.075\nINFO:tensorflow:loss = 0.36328506, step = 1600 (0.351 sec)\nINFO:tensorflow:global_step/sec: 314.51\nINFO:tensorflow:loss = 0.47097665, step = 1700 (0.316 sec)\nINFO:tensorflow:global_step/sec: 275.262\nINFO:tensorflow:loss = 0.6490936, step = 1800 (0.362 sec)\nINFO:tensorflow:global_step/sec: 278.425\nINFO:tensorflow:loss = 0.51483405, step = 1900 (0.363 sec)\nINFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\nINFO:tensorflow:Saving checkpoints for 2000 into ./graphs/dnn\\model.ckpt.\nINFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\nINFO:tensorflow:Loss for final step: 0.5388107.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1ef9b9d9508>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Train the DNN estimator\n",
    "\n",
    "#Create an instance of input train function\n",
    "input_train_fn = create_train_input_fn()\n",
    "# Train DNN estimator in input train function\n",
    "# Here training resumes from the latest check point\n",
    "# Inorder to start training from the beginning, make sure that you clear the graph/dnn directory before training\n",
    "estimator.train(input_train_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2020-07-04T20:08:21Z\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from ./graphs/dnn\\model.ckpt-2000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Inference Time : 0.92568s\nINFO:tensorflow:Finished evaluation at 2020-07-04-20:08:22\nINFO:tensorflow:Saving dict for global step 2000: accuracy = 0.83798885, accuracy_baseline = 0.61452514, auc = 0.902635, auc_precision_recall = 0.87680256, average_loss = 0.4595023, global_step = 2000, label/mean = 0.38547486, loss = 0.4433565, precision = 0.82258064, prediction/mean = 0.3826476, recall = 0.73913044\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: ./graphs/dnn\\model.ckpt-2000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': 0.83798885,\n 'accuracy_baseline': 0.61452514,\n 'auc': 0.902635,\n 'auc_precision_recall': 0.87680256,\n 'average_loss': 0.4595023,\n 'label/mean': 0.38547486,\n 'loss': 0.4433565,\n 'precision': 0.82258064,\n 'prediction/mean': 0.3826476,\n 'recall': 0.73913044,\n 'global_step': 2000}"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "input_test_fn = create_test_input_fn()\n",
    "estimator.evaluate(input_test_fn) # This will print the test accuracy along with other performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from ./graphs/dnn\\model.ckpt-2000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n\n Example : 0 \t Actual : 1.0 \t Predicted : 1\n\n Example : 1 \t Actual : 1.0 \t Predicted : 1\n\n Example : 2 \t Actual : 1.0 \t Predicted : 0\n\n Example : 3 \t Actual : 0.0 \t Predicted : 0\n\n Example : 4 \t Actual : 0.0 \t Predicted : 0\n\n Example : 5 \t Actual : 1.0 \t Predicted : 1\n\n Example : 6 \t Actual : 1.0 \t Predicted : 1\n\n Example : 7 \t Actual : 1.0 \t Predicted : 1\n\n Example : 8 \t Actual : 0.0 \t Predicted : 0\n\n Example : 9 \t Actual : 0.0 \t Predicted : 0\n"
    }
   ],
   "source": [
    "# Predict output\n",
    "input_test_fn = create_test_input_fn()\n",
    "result = estimator.predict(input_test_fn)\n",
    "\n",
    "# Verify results\n",
    "i = 0\n",
    "for res,actual_result in zip(result, test_label):\n",
    "    predicted_result = res['class_ids'][0]\n",
    "    print(\"\\n Example : {} \\t Actual : {} \\t Predicted : {}\".format(i, actual_result, predicted_result))\n",
    "\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can see DNN Classifier performing well over the test set than the Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37332bit5bf175bf0eae454eac773f0ede690b75",
   "display_name": "Python 3.7.3 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}